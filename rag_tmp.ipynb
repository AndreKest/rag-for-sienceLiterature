{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a9596a54-3810-4b18-ab2d-7dde9cf08e69",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "import transformers\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM,  BitsAndBytesConfig\n",
    "import torch\n",
    "\n",
    "import os\n",
    "import dotenv\n",
    "dotenv.load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "356b1b4f-4102-492e-ac75-71e185ae3f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7509, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titel</th>\n",
       "      <th>header</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main_body</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>pages</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning Disentangled Representations of Negat...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nNegation and uncertainty modeling ar...</td>\n",
       "      <td>1 Introduction\\nIn formal semantics, negation...</td>\n",
       "      <td>\\nReferences\\nHeike Adel and Hinrich Sch端tze. ...</td>\n",
       "      <td>Abstract\\nNegation and uncertainty modeling a...</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation Graph Generation via Pre-trained L...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nPre-trained sequence-to-sequence lan...</td>\n",
       "      <td>1 Introduction\\nPre-trained sequence-to-seque...</td>\n",
       "      <td>\\nReferences\\nYonatan Bisk, Rowan Zellers, Jia...</td>\n",
       "      <td>Abstract\\nPre-trained sequence-to-sequence la...</td>\n",
       "      <td>2022</td>\n",
       "      <td>19</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Updated Headline Generation Creating Updated S...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nWe propose the task of updated headl...</td>\n",
       "      <td>1 Introduction\\nAutomatic text summarization ...</td>\n",
       "      <td>reference, we also eval-\\nuate the gold headl...</td>\n",
       "      <td>Abstract\\nWe propose the task of updated head...</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conditional Bilingual Mutual Information Based...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nToken-level adaptive training approa...</td>\n",
       "      <td>1 Introduction\\nNeural machine translation (N...</td>\n",
       "      <td>\\nReferences\\nDzmitry Bahdanau, Kyunghyun Cho,...</td>\n",
       "      <td>Abstract\\nToken-level adaptive training appro...</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReCLIP A Strong Zero-Shot Baseline for Referri...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nTraining a referring expression comp...</td>\n",
       "      <td>1 Introduction\\nVisual referring expression c...</td>\n",
       "      <td>references the\\ncolor in the text prompt to s...</td>\n",
       "      <td>Abstract\\nTraining a referring expression com...</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titel  \\\n",
       "0  Learning Disentangled Representations of Negat...   \n",
       "1  Explanation Graph Generation via Pre-trained L...   \n",
       "2  Updated Headline Generation Creating Updated S...   \n",
       "3  Conditional Bilingual Mutual Information Based...   \n",
       "4  ReCLIP A Strong Zero-Shot Baseline for Referri...   \n",
       "\n",
       "                                              header  \\\n",
       "0  Proceedings of the 60th Annual Meeting of the ...   \n",
       "1  Proceedings of the 60th Annual Meeting of the ...   \n",
       "2  Proceedings of the 60th Annual Meeting of the ...   \n",
       "3  Proceedings of the 60th Annual Meeting of the ...   \n",
       "4  Proceedings of the 60th Annual Meeting of the ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract\\nNegation and uncertainty modeling ar...   \n",
       "1  Abstract\\nPre-trained sequence-to-sequence lan...   \n",
       "2  Abstract\\nWe propose the task of updated headl...   \n",
       "3  Abstract\\nToken-level adaptive training approa...   \n",
       "4  Abstract\\nTraining a referring expression comp...   \n",
       "\n",
       "                                           main_body  \\\n",
       "0   1 Introduction\\nIn formal semantics, negation...   \n",
       "1   1 Introduction\\nPre-trained sequence-to-seque...   \n",
       "2   1 Introduction\\nAutomatic text summarization ...   \n",
       "3   1 Introduction\\nNeural machine translation (N...   \n",
       "4   1 Introduction\\nVisual referring expression c...   \n",
       "\n",
       "                                          references  \\\n",
       "0  \\nReferences\\nHeike Adel and Hinrich Sch端tze. ...   \n",
       "1  \\nReferences\\nYonatan Bisk, Rowan Zellers, Jia...   \n",
       "2   reference, we also eval-\\nuate the gold headl...   \n",
       "3  \\nReferences\\nDzmitry Bahdanau, Kyunghyun Cho,...   \n",
       "4   references the\\ncolor in the text prompt to s...   \n",
       "\n",
       "                                                text  year  pages conference  \n",
       "0   Abstract\\nNegation and uncertainty modeling a...  2022     18        acl  \n",
       "1   Abstract\\nPre-trained sequence-to-sequence la...  2022     19        acl  \n",
       "2   Abstract\\nWe propose the task of updated head...  2022     24        acl  \n",
       "3   Abstract\\nToken-level adaptive training appro...  2022     13        acl  \n",
       "4   Abstract\\nTraining a referring expression com...  2022     18        acl  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "path = './data/acl_main_20102024.pkl'\n",
    "data_acl = pd.read_pickle(path)\n",
    "\n",
    "print(data_acl.shape)\n",
    "data_acl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab22896-8c95-46e8-8f77-0b482bb57fd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7706, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titel</th>\n",
       "      <th>header</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main_body</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>pages</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Generating Summaries with Controllable Readabi...</td>\n",
       "      <td>Proceedings of the 2023 Conference on Empirica...</td>\n",
       "      <td>Abstract\\nReadability refers to how easily a r...</td>\n",
       "      <td>1 Introduction\\nSummaries convey salient piec...</td>\n",
       "      <td>reference summary; that way,\\nthe model can l...</td>\n",
       "      <td>Abstract\\nReadability refers to how easily a ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>19</td>\n",
       "      <td>emnlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AMR Parsing is Far from Solved GrAPES, the Gra...</td>\n",
       "      <td>Proceedings of the 2023 Conference on Empirica...</td>\n",
       "      <td>Abstract\\nWe present the Granular AMR Parsing ...</td>\n",
       "      <td>1 Introduction\\nAbstract Meaning Representati...</td>\n",
       "      <td>references for each possible\\nreading.\\nEthic...</td>\n",
       "      <td>Abstract\\nWe present the Granular AMR Parsing...</td>\n",
       "      <td>2023</td>\n",
       "      <td>25</td>\n",
       "      <td>emnlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ViT-TTS Visual Text-to-Speech with Scalable Di...</td>\n",
       "      <td>Proceedings of the 2023 Conference on Empirica...</td>\n",
       "      <td>Abstract\\nText-to-speech(TTS) has undergone re...</td>\n",
       "      <td>1 Introduction\\nText-to-speech (TTS) (Ren et ...</td>\n",
       "      <td>reference samples in terms of\\nsemantic meani...</td>\n",
       "      <td>Abstract\\nText-to-speech(TTS) has undergone r...</td>\n",
       "      <td>2023</td>\n",
       "      <td>13</td>\n",
       "      <td>emnlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>XLM-V Overcoming the Vocabulary Bottleneck in ...</td>\n",
       "      <td>Proceedings of the 2023 Conference on Empirica...</td>\n",
       "      <td>Abstract\\nLarge multilingual language models t...</td>\n",
       "      <td>1 Introduction\\nWhile multilingual language m...</td>\n",
       "      <td>\\nReferences\\nDavid Ifeoluwa Adelani, Jade Abb...</td>\n",
       "      <td>Abstract\\nLarge multilingual language models ...</td>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>emnlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FAME Flexible, Scalable Analogy Mappings Engine</td>\n",
       "      <td>Proceedings of the 2023 Conference on Empirica...</td>\n",
       "      <td>Abstract\\nAnalogy is one of the core capacitie...</td>\n",
       "      <td>1 Introduction\\nOne of the pinnacles of human...</td>\n",
       "      <td>\\nReferences\\nCarl Allen and Timothy Hospedale...</td>\n",
       "      <td>Abstract\\nAnalogy is one of the core capaciti...</td>\n",
       "      <td>2023</td>\n",
       "      <td>17</td>\n",
       "      <td>emnlp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titel  \\\n",
       "0  Generating Summaries with Controllable Readabi...   \n",
       "1  AMR Parsing is Far from Solved GrAPES, the Gra...   \n",
       "2  ViT-TTS Visual Text-to-Speech with Scalable Di...   \n",
       "3  XLM-V Overcoming the Vocabulary Bottleneck in ...   \n",
       "4    FAME Flexible, Scalable Analogy Mappings Engine   \n",
       "\n",
       "                                              header  \\\n",
       "0  Proceedings of the 2023 Conference on Empirica...   \n",
       "1  Proceedings of the 2023 Conference on Empirica...   \n",
       "2  Proceedings of the 2023 Conference on Empirica...   \n",
       "3  Proceedings of the 2023 Conference on Empirica...   \n",
       "4  Proceedings of the 2023 Conference on Empirica...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract\\nReadability refers to how easily a r...   \n",
       "1  Abstract\\nWe present the Granular AMR Parsing ...   \n",
       "2  Abstract\\nText-to-speech(TTS) has undergone re...   \n",
       "3  Abstract\\nLarge multilingual language models t...   \n",
       "4  Abstract\\nAnalogy is one of the core capacitie...   \n",
       "\n",
       "                                           main_body  \\\n",
       "0   1 Introduction\\nSummaries convey salient piec...   \n",
       "1   1 Introduction\\nAbstract Meaning Representati...   \n",
       "2   1 Introduction\\nText-to-speech (TTS) (Ren et ...   \n",
       "3   1 Introduction\\nWhile multilingual language m...   \n",
       "4   1 Introduction\\nOne of the pinnacles of human...   \n",
       "\n",
       "                                          references  \\\n",
       "0   reference summary; that way,\\nthe model can l...   \n",
       "1   references for each possible\\nreading.\\nEthic...   \n",
       "2   reference samples in terms of\\nsemantic meani...   \n",
       "3  \\nReferences\\nDavid Ifeoluwa Adelani, Jade Abb...   \n",
       "4  \\nReferences\\nCarl Allen and Timothy Hospedale...   \n",
       "\n",
       "                                                text  year  pages conference  \n",
       "0   Abstract\\nReadability refers to how easily a ...  2023     19      emnlp  \n",
       "1   Abstract\\nWe present the Granular AMR Parsing...  2023     25      emnlp  \n",
       "2   Abstract\\nText-to-speech(TTS) has undergone r...  2023     13      emnlp  \n",
       "3   Abstract\\nLarge multilingual language models ...  2023     11      emnlp  \n",
       "4   Abstract\\nAnalogy is one of the core capaciti...  2023     17      emnlp  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "path = './data/emnlp_main_20102024.pkl'\n",
    "data_emnlp = pd.read_pickle(path)\n",
    "\n",
    "print(data_emnlp.shape)\n",
    "data_emnlp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83ad096-3cff-4aa3-b038-31b42edb6de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15215, 9)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine dataframes\n",
    "data = pd.concat([data_acl, data_emnlp])\n",
    "for col in data.columns:\n",
    "    try:\n",
    "        data[col] = data[col].str.encode('utf-8', errors='ignore').str.decode('utf-8')\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7537aa6d-1932-4806-ab31-147c995554d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>titel</th>\n",
       "      <th>header</th>\n",
       "      <th>abstract</th>\n",
       "      <th>main_body</th>\n",
       "      <th>references</th>\n",
       "      <th>text</th>\n",
       "      <th>year</th>\n",
       "      <th>pages</th>\n",
       "      <th>conference</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Learning Disentangled Representations of Negat...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nNegation and uncertainty modeling ar...</td>\n",
       "      <td>1 Introduction\\nIn formal semantics, negation...</td>\n",
       "      <td>\\nReferences\\nHeike Adel and Hinrich Sch端tze. ...</td>\n",
       "      <td>Abstract\\nNegation and uncertainty modeling a...</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Explanation Graph Generation via Pre-trained L...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nPre-trained sequence-to-sequence lan...</td>\n",
       "      <td>1 Introduction\\nPre-trained sequence-to-seque...</td>\n",
       "      <td>\\nReferences\\nYonatan Bisk, Rowan Zellers, Jia...</td>\n",
       "      <td>Abstract\\nPre-trained sequence-to-sequence la...</td>\n",
       "      <td>2022</td>\n",
       "      <td>19</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Updated Headline Generation Creating Updated S...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nWe propose the task of updated headl...</td>\n",
       "      <td>1 Introduction\\nAutomatic text summarization ...</td>\n",
       "      <td>reference, we also eval-\\nuate the gold headl...</td>\n",
       "      <td>Abstract\\nWe propose the task of updated head...</td>\n",
       "      <td>2022</td>\n",
       "      <td>24</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Conditional Bilingual Mutual Information Based...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nToken-level adaptive training approa...</td>\n",
       "      <td>1 Introduction\\nNeural machine translation (N...</td>\n",
       "      <td>\\nReferences\\nDzmitry Bahdanau, Kyunghyun Cho,...</td>\n",
       "      <td>Abstract\\nToken-level adaptive training appro...</td>\n",
       "      <td>2022</td>\n",
       "      <td>13</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ReCLIP A Strong Zero-Shot Baseline for Referri...</td>\n",
       "      <td>Proceedings of the 60th Annual Meeting of the ...</td>\n",
       "      <td>Abstract\\nTraining a referring expression comp...</td>\n",
       "      <td>1 Introduction\\nVisual referring expression c...</td>\n",
       "      <td>references the\\ncolor in the text prompt to s...</td>\n",
       "      <td>Abstract\\nTraining a referring expression com...</td>\n",
       "      <td>2022</td>\n",
       "      <td>18</td>\n",
       "      <td>acl</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               titel  \\\n",
       "0  Learning Disentangled Representations of Negat...   \n",
       "1  Explanation Graph Generation via Pre-trained L...   \n",
       "2  Updated Headline Generation Creating Updated S...   \n",
       "3  Conditional Bilingual Mutual Information Based...   \n",
       "4  ReCLIP A Strong Zero-Shot Baseline for Referri...   \n",
       "\n",
       "                                              header  \\\n",
       "0  Proceedings of the 60th Annual Meeting of the ...   \n",
       "1  Proceedings of the 60th Annual Meeting of the ...   \n",
       "2  Proceedings of the 60th Annual Meeting of the ...   \n",
       "3  Proceedings of the 60th Annual Meeting of the ...   \n",
       "4  Proceedings of the 60th Annual Meeting of the ...   \n",
       "\n",
       "                                            abstract  \\\n",
       "0  Abstract\\nNegation and uncertainty modeling ar...   \n",
       "1  Abstract\\nPre-trained sequence-to-sequence lan...   \n",
       "2  Abstract\\nWe propose the task of updated headl...   \n",
       "3  Abstract\\nToken-level adaptive training approa...   \n",
       "4  Abstract\\nTraining a referring expression comp...   \n",
       "\n",
       "                                           main_body  \\\n",
       "0   1 Introduction\\nIn formal semantics, negation...   \n",
       "1   1 Introduction\\nPre-trained sequence-to-seque...   \n",
       "2   1 Introduction\\nAutomatic text summarization ...   \n",
       "3   1 Introduction\\nNeural machine translation (N...   \n",
       "4   1 Introduction\\nVisual referring expression c...   \n",
       "\n",
       "                                          references  \\\n",
       "0  \\nReferences\\nHeike Adel and Hinrich Sch端tze. ...   \n",
       "1  \\nReferences\\nYonatan Bisk, Rowan Zellers, Jia...   \n",
       "2   reference, we also eval-\\nuate the gold headl...   \n",
       "3  \\nReferences\\nDzmitry Bahdanau, Kyunghyun Cho,...   \n",
       "4   references the\\ncolor in the text prompt to s...   \n",
       "\n",
       "                                                text  year  pages conference  \n",
       "0   Abstract\\nNegation and uncertainty modeling a...  2022     18        acl  \n",
       "1   Abstract\\nPre-trained sequence-to-sequence la...  2022     19        acl  \n",
       "2   Abstract\\nWe propose the task of updated head...  2022     24        acl  \n",
       "3   Abstract\\nToken-level adaptive training appro...  2022     13        acl  \n",
       "4   Abstract\\nTraining a referring expression com...  2022     18        acl  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2864f66-8495-4f9f-a2d4-0016e17050b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15215"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataFrameLoader(data, page_content_column='text')\n",
    "docs = loader.load()\n",
    "len(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6cca4879-2aba-4617-aebe-cf311503f0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split text\n",
    "splitter = RecursiveCharacterTextSplitter(chunk_size=2048, chunk_overlap=30)\n",
    "chunked_docs = splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f00408f4-e503-485e-92b3-8b674a11114a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embeddings\n",
    "model_name = \"BAAI/bge-base-en-v1.5\"\n",
    "model_kwargs = {'device': 'cpu'}\n",
    "encode_kwargs = {'normalize_embeddings': False}\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=model_name,\n",
    "    #model_kwargs=model_kwargs,\n",
    "    #encode_kwargs=encode_kwargs,\n",
    "    cache_folder = './hf'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b884f84b-a641-452a-839a-0c149ca90d1b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "db = FAISS.from_documents(chunked_docs, embeddings)\n",
    "db.save_local(\"faiss_index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf387d01-c358-474b-a72f-c657643940d0",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "db = FAISS.load_local(\"faiss_index\", embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "retriever = db.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 4})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9a94d26-dc87-4bba-ad90-920290ed1595",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TextStreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17a493f3-a009-417a-a0da-48f133146602",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f878f0ba74c940dbb0ebcbf042f57352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/855 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa306b4bef442b58c237aa884f551ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors.index.json:   0%|          | 0.00/23.9k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "083227e3b3e64e4cbdacd8082c3e874d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Fetching 4 files:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e82414f87e2463ca74d5bf83021803c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00004-of-00004.safetensors:   0%|          | 0.00/1.17G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb8bc5eeddd6430390416b507edf02a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00003-of-00004.safetensors:   0%|          | 0.00/4.92G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c1a3fffc2147d8b311307038143b9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00001-of-00004.safetensors:   0%|          | 0.00/4.98G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98570da86b542f195b028ec367c5492",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model-00002-of-00004.safetensors:   0%|          | 0.00/5.00G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba730e8fc3e144ee8c8b70320cdc99b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65fca747824640c68fc154bb5acf3e4a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/184 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ce64200e7f64f34a3c8bd527448a854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/55.4k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dc615bb175f4506867474785f2aabf2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.09M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9cc5183c90349a3be5be8e082d1bd9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = \"meta-llama/Llama-3.1-8B-Instruct\"\n",
    "config = BitsAndBytesConfig(\n",
    "    load_in_4bit=True, bnb_4bit_use_double_quant=True, bnb_4bit_quant_type=\"nf4\", bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=config, device_map=\"auto\", token=os.environ['hf_token'])\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name, token=os.environ['hf_token'])\n",
    "\n",
    "streamer = TextStreamer(tokenizer, skip_prompt=True, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5229e859-5ae5-426c-b1b0-06184bb6d6ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import ChatHuggingFace, HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6bd7e54-452f-44f6-96be-2dfb18102230",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:1\n"
     ]
    }
   ],
   "source": [
    "pipe = transformers.pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=200, streamer=streamer)\n",
    "\n",
    "llm = HuggingFacePipeline(model_id=model_name, pipeline=pipe)\n",
    "llm = ChatHuggingFace(llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d43d86a1-9eb9-4cc0-b2b2-5cc1510d9a8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm just a language model, so I don't have feelings or emotions like humans do, but I'm functioning properly and ready to assist you with any questions or tasks you have. How can I help you today?\n"
     ]
    }
   ],
   "source": [
    "res = llm.invoke(\"hi how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d71e5cca-26f3-4e09-9283-b07dfca4488f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/kesa/projects/rag-for-sienceLiterature/my-env/lib/python3.10/site-packages/langsmith/client.py:277: LangSmithMissingAPIKeyWarning: API key must be provided when using hosted LangSmith API\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain import hub\n",
    "prompt = hub.pull(\"rlm/rag-prompt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13b9d5dc-4cfb-40c6-ad14-51c309e5f233",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "from transformers import pipeline, TextStreamer\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "<|system|>\n",
    "Answer the question based on the following context:\n",
    "\n",
    "{context}\n",
    "\n",
    "</s>\n",
    "<|user|>\n",
    "{question}\n",
    "</s>\n",
    "<|assistant|>\n",
    "\n",
    " \"\"\"\n",
    "\n",
    "prompt = PromptTemplate(\n",
    "    input_variables=[\"context\", \"question\"],\n",
    "    template=prompt_template,\n",
    ")\n",
    "\n",
    "llm_chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e81c121b-62fd-4c80-a550-a2b74d3b7a8e",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | llm_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "929d6ffc-dca4-4368-8e5a-f48d509603d9",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Chain of Thought (CoT) method was introduced by researchers at the University of California, Berkeley, and has since been developed and improved by various researchers.\n"
     ]
    }
   ],
   "source": [
    "question = \"Who invented the Chain of Thought method?\"\n",
    "res = rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "114f044c-173a-4c02-96aa-8d82434a6459",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task-oriented dialogue systems are designed to assist users in achieving specific goals or tasks through conversations. These systems aim to understand the user's intent, provide relevant information, and guide the user through the task completion process. They are often used in various domains such as customer service, education, and healthcare.\n",
      "\n",
      "In a task-oriented dialogue system, the user typically initiates a conversation by stating their goal or task, and the system responds with a series of questions or prompts to clarify the user's intent and gather necessary information. The system then uses this information to provide relevant guidance, instructions, or answers to help the user complete the task.\n",
      "\n",
      "Task-oriented dialogue systems can be categorized into two main types:\n",
      "\n",
      "1. **Goal-oriented dialogue systems**: These systems are designed to achieve a specific goal or task, such as booking a flight, making a reservation, or answering a question.\n",
      "2. **Procedural dialogue systems**: These systems guide the user through a series of steps to complete a task, such as creating a\n"
     ]
    }
   ],
   "source": [
    "question = \"What are Task Oriented Dialoge systems?\"\n",
    "res = rag_chain.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86cb2276-cebe-45a0-befa-ccf29c6fcc38",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from langchain.chains import RetrievalQA\n",
    "qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"refine\", retriever=retriever, return_source_documents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ebb6cfff-882a-4e8f-b50e-2600fbbc551f",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought (CoT) is an approach to artificial intelligence, specifically in the context of Large Language Models (LLMs), that encourages the model to articulate a step-by-step reasoning process leading to the final answer. This approach is supported by in-context demonstrations, which means that the model is provided with a prompt or context that guides its reasoning and helps it to arrive at a solution.\n",
      "\n",
      "In essence, CoT is a way of training LLMs to think like humans, by having them explain their thought process and reasoning behind their answers. This is in contrast to more traditional approaches that simply provide a final answer without explaining the reasoning behind it.\n",
      "\n",
      "CoT is often used in conjunction with other approaches, such as Logic-LM, Tree-of-Thought (ToT), Cumulative Reasoning (CR), and DetermLR, to improve the performance and efficiency of the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought (CoT) is an approach to artificial intelligence that encourages a Large Language Model (LLM) to articulate a step-by-step reasoning process leading to the final answer. This approach is supported by in-context demonstrations, where the model is guided by a prompt or context to arrive at a solution.\n",
      "\n",
      "CoT is a method of reasoning that breaks down complex problems into manageable steps, creating a chain of thoughts that links these steps together, ensuring that no important conditions are overlooked. This approach provides an observable reasoning process, allowing users to understand the model's decision-making trajectory and increasing the trustworthiness and interpretability of the final answer.\n",
      "\n",
      "The benefits of CoT prompting have led to its widespread attention in both academia and industry, evolving into a distinct research branch within the field of prompt engineering. It is also a crucial component in the landscape of AI autonomous agents. However, existing studies lack a systematic review and analysis, which this work aims to address by proposing a comprehensive and detailed analysis of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought (CoT) is a linear problem-solving approach that involves a step-by-step reasoning process, where each step builds upon the previous one. This approach has been applied to multi-step reasoning tasks, and various methods have been proposed to automate CoT, such as Auto-CoT, which constructs demonstrations by sampling diverse questions and generating reasoning chains.\n",
      "\n",
      "CoT has been combined with other techniques, including:\n",
      "\n",
      "1. **PS Prompt**: breaks tasks into subtasks\n",
      "2. **ToT**: expands on the reasoning process by considering multiple paths of reasoning and self-evaluating choices\n",
      "3. **effective GoT**: frames thoughts as graphs\n",
      "4. **Natural Program**: improves deductive reasoning tasks\n",
      "5. **Re-reading prompt**: revisits the question information embedded within input prompts\n",
      "\n",
      "Additionally, multi-agent discussion among LLMs has been explored as a method to improve reasoning abilities. This involves multiple LLMs discussing and reasoning given problems in an interactive way. Some notable frameworks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chain-of-Thought (CoT) is an approach to multi-hop question answering (QA) that involves breaking down questions into a sequence of reasoning steps before arriving at a final answer. However, traditional CoT approaches discard the intermediate steps and aggregate the final answers through a voting mechanism, which can lead to several shortcomings.\n",
      "\n",
      "To address these limitations, we introduce Multi-Chain Reasoning (MCR), an approach that prompts large language models to meta-reason over multiple chains of thought, rather than aggregating their answers. MCR examines different reasoning chains, mixes information between them, and selects the most relevant facts to generate an explanation and predict the answer.\n",
      "\n",
      "MCR outperforms strong baselines on 7 multi-hop QA datasets, and our analysis reveals that MCR explanations exhibit high quality, enabling humans to verify its answers.\n"
     ]
    }
   ],
   "source": [
    "question = \"What is Chain of Thought?\"\n",
    "result = qa.invoke({\"query\": question})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4dbb591f-b2ae-4ceb-8e97-ec181e3bbfcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Faithful Logical Reasoning via Symbolic Chain-of-Thought\n",
      "Navigate through Enigmatic Labyrinth A Survey of Chain of Thought Reasoning Advances, Frontiers and Future\n",
      "Rethinking the Bounds of LLM Reasoning Are Multi-Agent Discussions the Key\n",
      "Answering Questions by Meta-Reasoning over Multiple Chains of Thought\n"
     ]
    }
   ],
   "source": [
    "for doc in result['source_documents']:\n",
    "    print(doc.metadata['titel'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae8e379-9ae1-4ad7-a9f8-dcb0a69dced5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69dd0a11-6cc2-4eda-abfa-f1797c7737c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "\n",
    "from typing import Any, Dict, List\n",
    "\n",
    "from langchain import hub\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
    "from langchain.chains.retrieval import create_retrieval_chain\n",
    "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "from consts import INDEX_NAME\n",
    "\n",
    "\n",
    "def run_llm(query: str, chat_history: List[Dict[str, Any]] = []):\n",
    "    embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
    "    docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "    chat = ChatOpenAI(verbose=True, temperature=0)\n",
    "\n",
    "    rephrase_prompt = hub.pull(\"langchain-ai/chat-langchain-rephrase\")\n",
    "\n",
    "    retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "    stuff_documents_chain = create_stuff_documents_chain(chat, retrieval_qa_chat_prompt)\n",
    "\n",
    "    history_aware_retriever = create_history_aware_retriever(\n",
    "        llm=chat, retriever=docsearch.as_retriever(), prompt=rephrase_prompt\n",
    "    )\n",
    "    qa = create_retrieval_chain(\n",
    "        retriever=history_aware_retriever, combine_docs_chain=stuff_documents_chain\n",
    "    )\n",
    "\n",
    "    result = qa.invoke(input={\"input\": query, \"chat_history\": chat_history})\n",
    "    return result\n",
    "\n",
    "\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)\n",
    "\n",
    "\n",
    "def run_llm2(query: str, chat_history: List[Dict[str, Any]] = []):\n",
    "    embeddings = OpenAIEmbeddings()\n",
    "    docsearch = PineconeVectorStore(index_name=INDEX_NAME, embedding=embeddings)\n",
    "    chat = ChatOpenAI(model_name=\"gpt-4o\", verbose=True, temperature=0)\n",
    "\n",
    "    rephrase_prompt = hub.pull(\"langchain-ai/chat-langchain-rephrase\")\n",
    "\n",
    "    retrieval_qa_chat_prompt = hub.pull(\"langchain-ai/retrieval-qa-chat\")\n",
    "\n",
    "    rag_chain = (\n",
    "        {\n",
    "            \"context\": docsearch.as_retriever() | format_docs,\n",
    "            \"input\": RunnablePassthrough(),\n",
    "        }\n",
    "        | retrieval_qa_chat_prompt\n",
    "        | chat\n",
    "        | StrOutputParser()\n",
    "    )\n",
    "\n",
    "    retrieve_docs_chain = (lambda x: x[\"input\"]) | docsearch.as_retriever()\n",
    "\n",
    "    chain = RunnablePassthrough.assign(context=retrieve_docs_chain).assign(\n",
    "        answer=rag_chain\n",
    "    )\n",
    "\n",
    "    result = chain.invoke({\"input\": query, \"chat_history\": chat_history})\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my-env",
   "language": "python",
   "name": "my-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
